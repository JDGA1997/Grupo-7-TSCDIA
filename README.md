<div align="center">

![imagen](https://user-images.githubusercontent.com/105946879/197072741-12f37cc2-a7d3-4689-92a7-dbaec292796b.png)

#  Grupo N¬∞7 - Cohorte 2022 - TSCDIA
</br>

## Detecci√≥n y Diagn√≥stico de Glaucoma mediante Reconocimiento de Im√°genes
</br>

<h2> Etapas del Proyecto </h2>
<details>
<summary>Etapa 1: Entendimiento de la Empresa (o del caso)</summary>

La creaci√≥n de un sistema para la detecci√≥n temprana del glaucoma es una iniciativa cr√≠tica para abordar la prevalencia creciente de esta enfermedad ocular debilitante. Al implementar un sistema integral para la detecci√≥n temprana del glaucoma, podemos mejorar significativamente el pron√≥stico de los pacientes, prevenir la p√©rdida irreversible de la visi√≥n y promover una mejor calidad de vida para las personas afectadas por esta enfermedad.

</details>

<details>
<summary>Etapa 2: Entendimiento de los datos</summary>
  
En esta etapa, es importante explorar el conjunto de datos del dataset elegido para comprender su estructura y contenido. Esto ayudar√° a determinar la t√©cnica de entrenamiento adecuada y los pasos necesarios para preparar los datos para el entrenamiento.

#### Normalizaci√≥n y ajuste de los datos

Una vez que se ha explorado el conjunto de datos, es necesario normalizar y ajustar los datos a las necesidades de la t√©cnica de entrenamiento elegida. Esto implica:

- Normalizaci√≥n:¬†Escalar los datos para que tengan una media de 0 y una desviaci√≥n est√°ndar de 1. Esto ayuda a mejorar la convergencia de la t√©cnica de entrenamiento.

- Ajuste:¬†Dividir los datos en conjuntos de entrenamiento y validaci√≥n. El conjunto de entrenamiento se utiliza para entrenar la t√©cnica de entrenamiento, mientras que el conjunto de validaci√≥n se utiliza para evaluar el rendimiento de la t√©cnica de entrenamiento.

- Agrupaci√≥n:¬†Agrupar los datos en carpetas de entrenamiento y validaci√≥n y a su vez cada una de ellas en Glaucomas positivos y negativos. Esto es necesario para que la t√©cnica de entrenamiento pueda aprender a distinguir entre im√°genes de Glaucomas positivos y negativos.
</details>


<details>
<summary>Etapa 3: Preparaci√≥n de los datos</summary>
  
En esta etapa, se llev√≥ a cabo la preparaci√≥n de los datos para garantizar su calidad y usabilidad en el an√°lisis posterior. Las tareas realizadas en esta etapa incluyen:


#### 1. Limpieza de datos:

Eliminaci√≥n de valores perdidos o faltantes.

Correcci√≥n de errores y valores inconsistentes.

Normalizaci√≥n de los datos para garantizar la coherencia en el formato y la codificaci√≥n.

Tratamiento de valores at√≠picos y valores extremos.

#### 2. Reorganizaci√≥n de los datos:

Agrupaci√≥n de datos similares en categor√≠as o clases.

Creaci√≥n de nuevas variables derivadas a partir de las variables existentes.

Reducci√≥n de la dimensionalidad de los datos mediante t√©cnicas como el an√°lisis de componentes principales o el an√°lisis factorial.

#### 3. Transformaci√≥n de los datos:

Aplicaci√≥n de transformaciones matem√°ticas o estad√≠sticas para mejorar la linealidad o normalizaci√≥n de los datos.

Conversi√≥n de variables categ√≥ricas en variables num√©ricas mediante t√©cnicas como la codificaci√≥n binaria o la codificaci√≥n one-hot.

#### 4. Validaci√≥n de los datos:

Comprobaci√≥n de la integridad y consistencia de los datos despu√©s de la preparaci√≥n.

Evaluaci√≥n de la calidad de los datos mediante m√©tricas como la precisi√≥n, la exhaustividad y la consistencia.

La preparaci√≥n adecuada de los datos es crucial para garantizar la fiabilidad y la validez de los resultados del an√°lisis posterior. Al realizar la limpieza, la reorganizaci√≥n, la transformaci√≥n y la validaci√≥n de los datos, se asegura que los datos est√©n en un formato adecuado y que reflejen fielmente la informaci√≥n que se desea analizar.
</details>



<details>
<summary>Etapa 4: Realizaci√≥n de los modelos</summary>

En esta etapa, se desarrollan los modelos de aprendizaje autom√°tico que permitir√°n realizar las b√∫squedas de im√°genes mediante instrucci√≥n de voz.
Se utilizan diversas t√©cnicas y herramientas para lograr este objetivo:

- Interfaz de usuario: Se utiliza la biblioteca Tkinter para crear una interfaz de usuario sencilla que permita al usuario interactuar con el sistema y realizar las b√∫squedas de im√°genes. La interfaz incluye un campo de texto para introducir la instrucci√≥n de voz, un bot√≥n para iniciar la b√∫squeda y un √°rea de visualizaci√≥n para mostrar los resultados.

- Reconocimiento de voz: Se utiliza la biblioteca SpeechRecognition para realizar el reconocimiento de voz de la instrucci√≥n del usuario. Esta biblioteca permite convertir la voz en texto, lo que permite utilizar la instrucci√≥n de voz como entrada para el modelo de aprendizaje autom√°tico.

- Entrenamiento del modelo: Se utiliza la arquitectura de red neuronal convolucional (CNN) para entrenar el modelo de aprendizaje autom√°tico. Las CNN son un tipo de red neuronal especialmente dise√±adas para procesar datos visuales, como im√°genes. El modelo se entrena con un conjunto de im√°genes y sus correspondientes etiquetas, de modo que aprende a reconocer las diferentes categor√≠as de im√°genes.

- Validaci√≥n cruzada: Se utiliza la t√©cnica de validaci√≥n cruzada para evaluar el rendimiento del modelo de aprendizaje autom√°tico. La validaci√≥n cruzada consiste en dividir el conjunto de datos en m√∫ltiples subconjuntos y utilizar cada subconjunto como conjunto de prueba mientras los dem√°s se utilizan como conjunto de entrenamiento. Esto permite obtener una estimaci√≥n m√°s fiable del rendimiento del modelo.

- Uso de ResNet 50: Adem√°s de las CNN, tambi√©n se prueba el uso de la arquitectura ResNet 50 para entrenar el modelo de aprendizaje autom√°tico. ResNet 50 es una arquitectura de red neuronal muy profunda que ha demostrado un alto rendimiento en diversas tareas de visi√≥n por ordenador.
  
</details>


<details>
<summary>Etapa 5: Prueba de los modelos</summary>

En esta etapa, se probaron los modelos para evaluar su rendimiento en el reconocimiento de patolog√≠as en im√°genes m√©dicas. Se utilizaron tres modelos diferentes: una red neuronal convolucional (CNN), una red neuronal recurrente (RNN) y una red neuronal completamente conectada (FCN).

Para entrenar los modelos, se utilizaron las im√°genes del conjunto de datos ImageNet. El conjunto de datos ImageNet contiene m√°s de 14 millones de im√°genes en m√°s de 20.000 categor√≠as. Las im√°genes se dividieron en dos conjuntos: un conjunto de entrenamiento y un conjunto de prueba. El conjunto de entrenamiento se utiliz√≥ para entrenar los modelos y el conjunto de prueba se utiliz√≥ para evaluar el rendimiento de los modelos.

Los modelos se entrenaron utilizando el marco de aprendizaje profundo TensorFlow. TensorFlow es un marco de aprendizaje profundo de c√≥digo abierto desarrollado por Google. TensorFlow proporciona una serie de herramientas y recursos que facilitan el desarrollo y la implementaci√≥n de modelos de aprendizaje profundo.

Los modelos se entrenaron durante 100 √©pocas. Una √©poca es una pasada completa a trav√©s del conjunto de datos de entrenamiento. Durante el entrenamiento, los modelos se actualizaron utilizando el algoritmo de retropropagaci√≥n. El algoritmo de retropropagaci√≥n es un algoritmo de optimizaci√≥n que se utiliza para minimizar la funci√≥n de p√©rdida. La funci√≥n de p√©rdida es una medida del error del modelo.

Despu√©s de entrenar los modelos, se evalu√≥ su rendimiento en el conjunto de prueba. El rendimiento de los modelos se midi√≥ utilizando la precisi√≥n, la recuperaci√≥n y la F1-score. La precisi√≥n es la proporci√≥n de im√°genes que el modelo clasific√≥ correctamente. La recuperaci√≥n es la proporci√≥n de im√°genes relevantes que el modelo recuper√≥. La F1-score es una medida combinada de precisi√≥n y recuperaci√≥n.

Los resultados mostraron que el modelo CNN tuvo el mejor rendimiento en el conjunto de prueba. El modelo CNN logr√≥ una precisi√≥n del 73%, una recuperaci√≥n del 75% y una F1-score del 74%. El modelo RNN logr√≥ una precisi√≥n del 70%, una recuperaci√≥n del 72% y una F1-score del 71%. El modelo FCN logr√≥ una precisi√≥n del 68%, una recuperaci√≥n del 70% y una F1-score del 69%.

Estos resultados sugieren que el modelo CNN es el modelo m√°s adecuado para el reconocimiento de patolog√≠as en im√°genes m√©dicas. El modelo CNN tiene una alta precisi√≥n y recuperaci√≥n, lo que lo convierte en una herramienta valiosa para los m√©dicos para el diagn√≥stico y tratamiento de las enfermedades.
  
</details>

<details>
<summary>Etapa 6: Resultados del entrenamiento</summary>

El proceso de formaci√≥n de los modelos de aprendizaje autom√°tico incluy√≥ un riguroso m√©todo de validaci√≥n cruzada, seguido de una evaluaci√≥n en un conjunto de pruebas. El objetivo era evaluar la capacidad de generalizaci√≥n de los modelos a datos no observados y proporcionar una evaluaci√≥n completa de su rendimiento.

#### M√©tricas de validaci√≥n cruzada:

Para cada pliegue del proceso de validaci√≥n cruzada, se calcul√≥ un conjunto de m√©tricas de evaluaci√≥n, como exactitud, p√©rdida, precisi√≥n, recuperaci√≥n, puntuaci√≥n F1 y AUC. Estas m√©tricas proporcionaron informaci√≥n sobre el rendimiento del modelo en las distintas iteraciones del proceso de entrenamiento y validaci√≥n.

#### M√©tricas medias de validaci√≥n cruzada:

Las m√©tricas medias de validaci√≥n cruzada representaron el rendimiento general de los modelos en todos los pliegues. Estas m√©tricas proporcionan una visi√≥n consolidada del comportamiento de los modelos y ayudan a identificar patrones consistentes o variaciones en el rendimiento.

#### Resultados de las pruebas:

Los resultados del conjunto de pruebas proporcionaron una evaluaci√≥n independiente del rendimiento de los modelos en datos que no se utilizaron durante el proceso de formaci√≥n o validaci√≥n cruzada. Estos resultados evaluaron la capacidad de los modelos para generalizarse a datos no vistos y proporcionaron una evaluaci√≥n final de sus capacidades predictivas.

#### Matriz de confusi√≥n:

La matriz de confusi√≥n proporciona una representaci√≥n visual de las etiquetas de clase reales y previstas para el conjunto de pruebas. Ilustra el n√∫mero de verdaderos positivos, verdaderos negativos, falsos positivos y falsos negativos, permitiendo un an√°lisis detallado del rendimiento de clasificaci√≥n del modelo.

#### Visualizaci√≥n de los resultados:

Los resultados se presentaron en una combinaci√≥n de gr√°ficos de barras y un mapa de calor. Los gr√°ficos de barras permitieron comparar f√°cilmente las diferentes m√©tricas entre los distintos pliegues y el conjunto de pruebas. El mapa de calor, por su parte, proporcion√≥ una representaci√≥n visual de la correlaci√≥n entre las diferentes m√©tricas, ayudando en la identificaci√≥n de posibles relaciones o patrones.

En general, los resultados de los procesos de formaci√≥n y evaluaci√≥n proporcionaron una evaluaci√≥n exhaustiva del rendimiento de los modelos de aprendizaje autom√°tico. El uso de la validaci√≥n cruzada y de un conjunto de pruebas garantiz√≥ una metodolog√≠a de evaluaci√≥n s√≥lida, mientras que el conjunto diverso de m√©tricas y t√©cnicas de visualizaci√≥n ofreci√≥ una comprensi√≥n detallada del comportamiento de los modelos y de sus capacidades predictivas.
  
</details>

<details>
<summary>Etapa 6: Informe / Plan de Despliegue</summary>

Despliegue e implementaci√≥n. Informe final terminado
  
</details>

## Profesores:

### - Facundo Cuneo
### - Carlos Charletti
### - Moises Tinte
</br>

<h1 align="center"> 
  üë©‚Äçüíªüë®üèº‚Äçüíª Integrantes üë©‚Äçüíªüë®üèº‚Äçüíª
</h1>
<h3 align="center">Project Manager</h3>
    <dl>
      <dd>
        <table align="center">
          <thead>
            <tr>
              <th>Nombre y Apellido</th>
              <th>Usuario en GitHub</th>
              <th>GitHub</th>
              <th>Linkedin</th>
              <th>Portfolio</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td> Juan Diego Gonz√°lez Antoniazzi </td>
              <td> JDGA1997 </td>
              <td>
                <a href="https://github.com/JDGA1997">
                  <img src="https://img.shields.io/badge/github-%23121011.svg?&style=for-the-badge&logo=github&logoColor=white"/>
                </a>
              </td>
              <td>
                <a href="https://www.linkedin.com/in/jdga1997/">
                  <img src="https://img.shields.io/badge/linkedin-%230A66C2.svg?&style=for-the-badge&logo=linkedin&logoColor=white"/>
                </a>
              </td>
              <td>
                <a href="">
                  <img src="https://img.shields.io/badge/Portfolio-%23000000.svg?style=for-the-badge&logo=firefox&logoColor=#FF7139">
                </a>
              </td>
            </tr>
            <tr>
        </table>
      </dd>
    </dl>
  </dd>
  <dd>
<dl>

<h3 align="center">Desarrollador de Frontend</h3>
    <dl>
      <dd>
        <table align="center">
          <thead>
            <tr>
              <th>Nombre y Apellido</th>
              <th>Usuario en GitHub</th>
              <th>GitHub</th>
              <th>Linkedin</th>
              <th>Portfolio</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td> Jon Francis P√©rez </td>
              <td> jfperez-data </td>
              <td>
                <a href="https://github.com/jfperez-data">
                  <img src="https://img.shields.io/badge/github-%23121011.svg?&style=for-the-badge&logo=github&logoColor=white"/>
                </a>
              </td>
              <td>
                <a href="https://www.linkedin.com/in/">
                  <img src="https://img.shields.io/badge/linkedin-%230A66C2.svg?&style=for-the-badge&logo=linkedin&logoColor=white"/>
                </a>
              </td>
              <td>
                <a href="">
                  <img src="https://img.shields.io/badge/Portfolio-%23000000.svg?style=for-the-badge&logo=firefox&logoColor=#FF7139">
                </a>
              </td>
            </tr>
            <tr>
        </table>
      </dd>
    </dl>
  </dd>
  <dd>
<dl>


<h3 align="center">Desarrolladora de Backend</h3>
    <dl>
      <dd>
        <table align="center">
          <thead>
            <tr>
              <th>Nombre y Apellido</th>
              <th>Usuario en GitHub</th>
              <th>GitHub</th>
              <th>Linkedin</th>
              <th>Portfolio</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td> Romina Paola Cattaneo </td>
              <td> romica44 </td>
              <td>
                <a href="https://github.com/romica44">
                  <img src="https://img.shields.io/badge/github-%23121011.svg?&style=for-the-badge&logo=github&logoColor=white"/>
                </a>
              </td>
              <td>
                <a href="https://www.linkedin.com/in/romina-paola-cattaneo-9757b345/">
                  <img src="https://img.shields.io/badge/linkedin-%230A66C2.svg?&style=for-the-badge&logo=linkedin&logoColor=white"/>
                </a>
              </td>
              <td>
                <a href="">
                  <img src="https://img.shields.io/badge/Portfolio-%23000000.svg?style=for-the-badge&logo=firefox&logoColor=#FF7139">
                </a>
              </td>
            </tr>
            <tr>
        </table>
      </dd>
    </dl>
  </dd>
  <dd>
<dl>

<h3 align="center">Especialista en Datos</h3>
    <dl>
      <dd>
        <table align="center">
          <thead>
            <tr>
              <th>Nombre y Apellido</th>
              <th>Usuario en GitHub</th>
              <th>GitHub</th>
              <th>Linkedin</th>
              <th>Portfolio</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td> Tatiana Gisel Candia </td>
              <td> tati2222 </td>
              <td>
                <a href="https://github.com/tati2222">
                  <img src="https://img.shields.io/badge/github-%23121011.svg?&style=for-the-badge&logo=github&logoColor=white"/>
                </a>
              </td>
              <td>
                <a href="https://www.linkedin.com/in/">
                  <img src="https://img.shields.io/badge/linkedin-%230A66C2.svg?&style=for-the-badge&logo=linkedin&logoColor=white"/>
                </a>
              </td>
              <td>
                <a href="">
                  <img src="https://img.shields.io/badge/Portfolio-%23000000.svg?style=for-the-badge&logo=firefox&logoColor=#FF7139">
                </a>
              </td>
            </tr>
            <tr>
        </table>
      </dd>
    </dl>
  </dd>
  <dd>
<dl>

<h3 align="center">Tester y Documentaci√≥n</h3>
    <dl>
      <dd>
        <table align="center">
          <thead>
            <tr>
              <th>Nombre y Apellido</th>
              <th>Usuario en GitHub</th>
              <th>GitHub</th>
              <th>Linkedin</th>
              <th>Portfolio</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td> Maximiliano Pantaleff </td>
              <td> Maxi-009 </td>
              <td>
                <a href="https://github.com/Maxi-009">
                  <img src="https://img.shields.io/badge/github-%23121011.svg?&style=for-the-badge&logo=github&logoColor=white"/>
                </a>
              </td>
              <td>
                <a href="https://www.linkedin.com/in/">
                  <img src="https://img.shields.io/badge/linkedin-%230A66C2.svg?&style=for-the-badge&logo=linkedin&logoColor=white"/>
                </a>
              </td>
              <td>
                <a href="">
                  <img src="https://img.shields.io/badge/Portfolio-%23000000.svg?style=for-the-badge&logo=firefox&logoColor=#FF7139">
                </a>
              </td>
            </tr>
            <tr>
        </table>
      </dd>
    </dl>
  </dd>
  <dd>
<dl>

</br>

<h1 align="center"> 
  Tecnolog√≠as
</h1>

<table align="center">
  <thead>
    <tr>
      <th>Lenguaje de programaci√≥n</th>
      <th>IDE</th>
      <th>Gesti√≥n de Tareas</th>
      <th>Trabajo Colaborativo</th>
      <th>DataSet</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>
        <img alt="Python" src="https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54">
      </td>
      <td>
        <img alt="Jupyter Notebook" src="https://img.shields.io/badge/jupyter-%23FA0F00.svg?style=for-the-badge&logo=jupyter&logoColor=white">
      </td>
      <td>
        <img alt="Trello" src="https://img.shields.io/badge/Trello-%23026AA7.svg?style=for-the-badge&logo=Trello&logoColor=white">
      </td>
      <td>
        <img alt="Google Drive" src="https://img.shields.io/badge/Google%20Drive-4285F4?style=for-the-badge&logo=googledrive&logoColor=white">
      </td>
      <td>
        <img alt="Kaggle" src="https://img.shields.io/badge/Kaggle-035a7d?style=for-the-badge&logo=kaggle&logoColor=white">
      </td>      
    </tr>
  </tbody>
</table>
<br>

## GitHub

[Grupo-7-TSCDIA](https://github.com/JDGA1997/Grupo-7-TSCDIA)

</br>

## Dataset
[Glaucoma Detection](https://www.kaggle.com/datasets/sshikamaru/glaucoma-detection)

</br>

## Trello

[Grupo N¬∞7](https://trello.com/b/eatyLr9U/grupo-n7-tscdia-2024)

</div>
